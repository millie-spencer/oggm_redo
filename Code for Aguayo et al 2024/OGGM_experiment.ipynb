{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bc6ce84-95d4-448e-a489-dbe3c4e9cb19",
   "metadata": {},
   "source": [
    "# OGGM experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcf4865-6547-405c-9293-8e169f3cf18e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# basic\n",
    "import os \n",
    "import psutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# geospatial\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "\n",
    "# oggm\n",
    "from oggm import cfg, utils, workflow, tasks\n",
    "from oggm.shop import gcm_climate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cfda8d-e16e-4934-9f39-fe1a40a325b3",
   "metadata": {},
   "source": [
    "## Setup and possible options "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488588d4-5f19-4d5c-8b48-19941e5eccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.initialize(logging_level='WORKFLOW', future = True)\n",
    "\n",
    "cfg.PARAMS['use_multiprocessing']  = True\n",
    "cfg.PARAMS['baseline_climate']     = ''\n",
    "cfg.PARAMS['prcp_scaling_factor']  = 1\n",
    "cfg.PARAMS['hydro_month_sh']       = 1\n",
    "cfg.PARAMS['hydro_month_nh']       = 1\n",
    "cfg.PARAMS['border']               = 80\n",
    "cfg.PARAMS['min_mu_star']          = 5\n",
    "cfg.PARAMS['max_mu_star']          = 800\n",
    "cfg.PARAMS['geodetic_mb_period']   = '2000-01-01_2020-01-01' \n",
    "cfg.PARAMS['store_model_geometry'] = True\n",
    "cfg.PARAMS['continue_on_error']    = True\n",
    "cfg.PARAMS['use_winter_prcp_factor'] = False\n",
    "\n",
    "# Potential historical scenario\n",
    "outlines    = [\"RGI7\", \"RGI6\"]          # Glacier outlines\n",
    "climate_ds  = [\"PMET\", \"CR2MET\", \"MSWEP\", \"ERA5\"]  # Climate baseline\n",
    "volume_ds   = [\"M22\", \"F19\"]            # Reference volume dataset \n",
    "\n",
    "# Potential future scenario\n",
    "gcm_list  = [\"ACCESS-CM2\", \"BCC-CSM2-MR\", \"CMCC-ESM2\", \"FGOALS-f3-L\", \"GFDL-ESM4\", \"CMCC-CM2-SR5\", \"KACE-1-0-G\", \"MPI-ESM1-2-HR\", \"MRI-ESM2-0\", \"MIROC6\"] # Climate models\n",
    "ssp_list  = [\"ssp126\",\"ssp245\", \"ssp370\", \"ssp585\"]   # Future scenarios\n",
    "bias_correction = [\"MVA\", \"DQM\", \"MBC\"]              # Bias correction method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31bbab9-f8dd-4ae1-b124-5187f25cd3e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calibration in the reference period (and commitment run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b6790c-31c0-4eda-9e7e-af265aa0f768",
   "metadata": {},
   "source": [
    "The complete workflow was divided according to tasks due to RAM limitations (only 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17e2a6c-1508-425e-bf41-34793bb82882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for rgi in outlines:\n",
    "    for file_id in climate_ds: \n",
    "        for volume in volume_ds:\n",
    "            \n",
    "            start = datetime.now()\n",
    "            \n",
    "            ids = gpd.read_file(\"/home/hydro/Dropbox/Patagonia/GIS South/Glaciers/\" + rgi + \"_v2.shp\")\n",
    "            ids = ids[ids.area_km2 > 1] # ~ 2,000 glaciers in each RGI\n",
    "            \n",
    "            cfg.PATHS['working_dir']  = \"/home/hydro/OGGM_results/\" + rgi + \"_\" + file_id + \"_\" + volume +\"_run\"\n",
    "            cfg.PATHS['climate_file'] = \"/home/hydro/OGGM_results/\" + file_id + \"_OGGM_1980_2019m.nc\"\n",
    "\n",
    "            if rgi == \"RGI6\":\n",
    "                # init directories\n",
    "                cfg.PARAMS['use_rgi_area'] = True\n",
    "                cfg.PARAMS['use_intersects'] = True\n",
    "                cfg.PARAMS['rgi_version'] = 62\n",
    "                base_url = 'https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.4/L1-L2_files/elev_bands/' # RGI 62\n",
    "                gdirs = workflow.init_glacier_directories(ids.RGIId, from_prepro_level=2, prepro_border = 80, prepro_base_url = base_url)\n",
    "\n",
    "            if rgi == \"RGI7\":\n",
    "                cfg.PARAMS['use_rgi_area'] = False\n",
    "                cfg.PARAMS['use_intersects'] = False\n",
    "                cfg.PARAMS['rgi_version'] = 7\n",
    "                \n",
    "                columns_ids = {'glac_id': 'GLIMSId', 'area_km2' : 'Area', 'glac_name': 'Name', 'Zone' : 'Zone', \n",
    "                               'vol_F19': 'vol_F19', 'vol_M22':'vol_M22', 'dmdtda_21' :'dmdtda_21'}\n",
    "                ids = utils.cook_rgidf(ids, o1_region='17', o2_region='02', bgndate= ids.src_date, version = \"70\",\n",
    "                              assign_column_values= columns_ids)\n",
    "                 \n",
    "                gdirs = workflow.init_glacier_directories(ids)\n",
    "                workflow.execute_entity_task(tasks.define_glacier_region, gdirs, source=\"NASADEM\");\n",
    "\n",
    "                task_list = [tasks.process_dem, tasks.simple_glacier_masks, tasks.elevation_band_flowline,\n",
    "                             tasks.fixed_dx_elevation_band_flowline, tasks.compute_downstream_line, tasks.compute_downstream_bedshape]\n",
    "             \n",
    "                for task in task_list:\n",
    "                    workflow.execute_entity_task(task, gdirs);\n",
    "\n",
    "            # write climate file for each glacier\n",
    "            workflow.execute_entity_task(tasks.process_custom_climate_data, gdirs);\n",
    "            \n",
    "            # calibration using huggonet et al. 2021            \n",
    "            ref_mb21 = ids.set_index(\"RGIId\").dmdtda_21*1000    \n",
    "            workflow.execute_entity_task(tasks.mu_star_calibration_from_geodetic_mb, \n",
    "                                             [(gdir, {'ref_mb': float(ref_mb21.loc[gdir.rgi_id])}) for gdir in gdirs]);\n",
    "            \n",
    "            # subset gdirs to avoid infinitive error messages\n",
    "            workflow.execute_entity_task(tasks.apparent_mb_from_any_mb, gdirs);\n",
    "            df = utils.compile_task_log(gdirs, task_names=[\"apparent_mb_from_any_mb\"])\n",
    "            df = df[df.apparent_mb_from_any_mb == \"SUCCESS\"]\n",
    "            gdirs = [gdir for gdir in gdirs if gdir.rgi_id in df.index.tolist()]\n",
    "\n",
    "            # inversion by catchment\n",
    "            for zone in range(1,10):\n",
    "                ids_subset = ids[ids.Zone == zone]\n",
    "                gdirs_subset = [gdir for gdir in gdirs if gdir.rgi_id in ids_subset.RGIId.tolist()]\n",
    "\n",
    "                if volume == \"M22\": # Millan et al. 2022 \n",
    "                    workflow.calibrate_inversion_from_consensus(gdirs_subset, volume_m3_reference = ids_subset.vol_M22.sum()*1e9,\n",
    "                                                                apply_fs_on_mismatch=True, error_on_mismatch=False, \n",
    "                                                                filter_inversion_output=True);\n",
    "                else: # Farinotti et al. 2019\n",
    "                    workflow.calibrate_inversion_from_consensus(gdirs_subset, volume_m3_reference = ids_subset.vol_F19.sum()*1e9,\n",
    "                                                                apply_fs_on_mismatch=True, error_on_mismatch=False, \n",
    "                                                                filter_inversion_output=True);\n",
    "            # ready to use (calibrate)\n",
    "            workflow.execute_entity_task(tasks.init_present_time_glacier, gdirs); \n",
    "\n",
    "            # calibration\n",
    "            workflow.execute_entity_task(tasks.run_with_hydro, \n",
    "                             [(gdir, {'ref_dmdtda': float(ref_mb21.loc[gdir.rgi_id])}) for gdir in gdirs], \n",
    "                             run_task = tasks.run_dynamic_mu_star_calibration, \n",
    "                             store_monthly_hydro=True, \n",
    "                             ys=1980,\n",
    "                             ye=2020,\n",
    "                             ref_area_from_y0=True,\n",
    "                             output_filesuffix= \"_\" + file_id,\n",
    "                             err_ref_dmdtda = 0.25*1000,\n",
    "                             mu_star_max_step_length = 10, \n",
    "                             maxiter = 20,         \n",
    "                             ignore_errors=True);\n",
    "\n",
    "            utils.compile_glacier_statistics(gdirs);  # save results\n",
    "            utils.compile_run_output(gdirs, input_filesuffix= \"_\" + file_id)\n",
    "\n",
    "            ## commitment run\n",
    "            workflow.execute_entity_task(tasks.run_with_hydro, gdirs,\n",
    "                                                 run_task = tasks.run_random_climate,\n",
    "                                                 seed = 123,\n",
    "                                                 nyears = 80, \n",
    "                                                 y0 = 2000, # central year of the random climate period. Has to be set!\n",
    "                                                 halfsize = 15, \n",
    "                                                 store_monthly_hydro = True, \n",
    "                                                 output_filesuffix = '_ct_random',\n",
    "                                                 init_model_filesuffix = \"_\" + file_id,  # this is important! Start from 2020 glacier\n",
    "                                                 ref_geometry_filesuffix = \"_\" + file_id,  # also use this as area reference\n",
    "                                                 ref_area_from_y0 = True)  # and keep the same reference area as for the hist simulations\n",
    "            utils.compile_run_output(gdirs, input_filesuffix='_ct_random')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474a35b8-8405-46ad-bd04-b08b3620f224",
   "metadata": {},
   "source": [
    "## Climate projections for each glacier and scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e48b07-d43c-4128-b550-ba26875bc48e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for rgi in outlines:\n",
    "    for file_id in climate_ds: \n",
    "        for volume in volume_ds:\n",
    "\n",
    "            ids = gpd.read_file(\"/home/hydro/Dropbox/Patagonia/GIS South/Glaciers/\" + rgi + \"_v2.shp\")\n",
    "            ids = ids[ids.area_km2 > 1] # ~ 2,000 glaciers in each RGI\n",
    "            \n",
    "            cfg.PATHS['working_dir']  = \"/home/hydro/OGGM_results/\" + rgi + \"_\" + file_id + \"_\" + volume +\"_run\"\n",
    "            cfg.PATHS['climate_file'] = \"/home/hydro/OGGM_results/\" + file_id + \"_OGGM_1980_2019m.nc\"\n",
    "\n",
    "            if rgi == \"RGI6\":\n",
    "                # init directories\n",
    "                cfg.PARAMS['use_rgi_area'] = True\n",
    "                cfg.PARAMS['use_intersects'] = True\n",
    "                cfg.PARAMS['rgi_version'] = 62\n",
    "\n",
    "            if rgi == \"RGI7\":\n",
    "                cfg.PARAMS['use_rgi_area'] = False\n",
    "                cfg.PARAMS['use_intersects'] = False\n",
    "                cfg.PARAMS['rgi_version'] = 7\n",
    "                \n",
    "                columns_ids = {'glac_id': 'GLIMSId', 'area_km2' : 'Area', 'glac_name': 'Name', 'Zone' : 'Zone', \n",
    "                               'vol_F19': 'vol_F19', 'vol_M22':'vol_M22', 'dmdtda_21' :'dmdtda_21'}\n",
    "                ids = utils.cook_rgidf(ids, o1_region='17', o2_region='02', bgndate= ids.src_date, version = \"70\",\n",
    "                              assign_column_values= columns_ids)\n",
    "                 \n",
    "            gdirs = workflow.init_glacier_directories(ids)\n",
    "\n",
    "            # future projections\n",
    "            for gcm in tqdm(gcm_list):    \n",
    "                for ssp in tqdm(ssp_list, leave = False):\n",
    "                    for bc in bias_correction:\n",
    "                        rid = \"_{}_{}_{}\".format(gcm, ssp, bc)\n",
    "\n",
    "                        # write future climate file (SSP-based) for each glacier\n",
    "                        workflow.execute_entity_task(gcm_climate.process_cmip_data, gdirs, filesuffix =  rid, \n",
    "                                                 fpath_precip = \"/home/hydro/OGGM_results/Future_climate_bc/PP_\" + file_id + rid + \".nc\", \n",
    "                                                 fpath_temp = \"/home/hydro/OGGM_results/Future_climate_bc/T2M_\" + file_id + rid + \".nc\", \n",
    "                                                 apply_bias_correction=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29e5cfc-7ece-46c5-b2b0-3a1f662e3299",
   "metadata": {},
   "source": [
    "## Glacier projections for each glacier and scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a616dc24-2701-4d8b-a2f0-34ff153a0d11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for rgi in outlines:\n",
    "    for file_id in climate_ds: \n",
    "        for volume in volume_ds:\n",
    "\n",
    "            ids = gpd.read_file(\"/home/hydro/Dropbox/Patagonia/GIS South/Glaciers/\" + rgi + \"_v2.shp\")\n",
    "            ids = ids[ids.area_km2 > 1] # ~ 2,000 glaciers in each RGI\n",
    "            \n",
    "            cfg.PATHS['working_dir']  = \"/home/hydro/OGGM_results/\" + rgi + \"_\" + file_id + \"_\" + volume +\"_run\"\n",
    "            cfg.PATHS['climate_file'] = \"/home/hydro/OGGM_results/\" + file_id + \"_OGGM_1980_2019m.nc\"\n",
    "\n",
    "            if rgi == \"RGI6\":\n",
    "                # init directories\n",
    "                cfg.PARAMS['use_rgi_area'] = True\n",
    "                cfg.PARAMS['use_intersects'] = True\n",
    "                cfg.PARAMS['rgi_version'] = 62\n",
    "\n",
    "            if rgi == \"RGI7\":\n",
    "                cfg.PARAMS['use_rgi_area'] = False\n",
    "                cfg.PARAMS['use_intersects'] = False\n",
    "                cfg.PARAMS['rgi_version'] = 7\n",
    "                \n",
    "                columns_ids = {'glac_id': 'GLIMSId', 'area_km2' : 'Area', 'glac_name': 'Name', 'Zone' : 'Zone', \n",
    "                               'vol_F19': 'vol_F19', 'vol_M22':'vol_M22', 'dmdtda_21' :'dmdtda_21'}\n",
    "                ids = utils.cook_rgidf(ids, o1_region='17', o2_region='02', bgndate= ids.src_date, version = \"70\",\n",
    "                              assign_column_values= columns_ids)\n",
    "                 \n",
    "            gdirs = workflow.init_glacier_directories(ids)\n",
    "\n",
    "            # subset gdirs to avoid infinitive error messages\n",
    "            df = pd.read_csv(cfg.PATHS['working_dir'] + \"/task_log.csv\")\n",
    "            df = df[df.apparent_mb_from_any_mb == \"SUCCESS\"]\n",
    "            gdirs = [gdir for gdir in gdirs if gdir.rgi_id in df.rgi_id.tolist()]\n",
    "                \n",
    "            for gcm in tqdm(gcm_list):    \n",
    "                for ssp in tqdm(ssp_list):\n",
    "                    for bc in bias_correction:\n",
    "                        rid = \"_{}_{}_{}\".format(gcm, ssp, bc)\n",
    "\n",
    "                        # run the glacier using hydro function \n",
    "                        workflow.execute_entity_task(tasks.run_with_hydro, gdirs, run_task = tasks.run_from_climate_data,\n",
    "                                                 climate_filename = 'gcm_data',  # use gcm_data, not climate_historical\n",
    "                                                 climate_input_filesuffix = rid,  # use the chosen scenario\n",
    "                                                 init_model_filesuffix = \"_\" + file_id,  # this is important! Start from 2020 glacier\n",
    "                                                 ref_geometry_filesuffix = \"_\" + file_id,  # also use this as area reference\n",
    "                                                 ref_area_from_y0 = True,  # and keep the same reference area as for the hist simulations\n",
    "                                                 output_filesuffix = rid,  # recognize the run for later\n",
    "                                                 store_monthly_hydro = True)  # add monthly diagnostics\n",
    "                        utils.compile_run_output(gdirs, input_filesuffix=rid)\n",
    "\n",
    "                    print(rgi, file_id, volume, gcm, ssp, datetime.now()-start, \"RAM memory % used:\", psutil.virtual_memory()[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb09f95-ea7a-4fed-bfd0-210f39b5600a",
   "metadata": {},
   "source": [
    "## Post-processing: Glacier time series for each catchment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa181885-50e7-484e-b321-a73295fb9747",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['volume', 'area', 'melt_on_glacier', 'melt_off_glacier', 'liq_prcp_off_glacier', 'liq_prcp_on_glacier']\n",
    "variables_final = ['volume', 'area', 'melt_on_glacier', 'total_runoff']\n",
    "\n",
    "def preprocess(ds): # remove unnecessary variables and coordinates\n",
    "    return ds.drop_vars(['hydro_year', 'hydro_month', 'calendar_year', 'calendar_month'])[variables]\n",
    "\n",
    "def compute_variables(ds): # calculate total_runoff and melt_on_glacier \n",
    "    ds[\"total_runoff\"] = ((ds.melt_off_glacier + ds.melt_on_glacier + ds.liq_prcp_off_glacier + ds.liq_prcp_on_glacier)*1e-3)/(365*86400) # m3/s\n",
    "    ds[\"melt_on_glacier\"] = ((ds.melt_on_glacier)*1e-3)/(365*86400) # m3/s\n",
    "    return ds[variables_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23507253-04d1-4766-bbd1-b1f708d03feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RGI6_ids = gpd.read_file(\"/home/rooda/Dropbox/Patagonia/GIS South/Glaciers/RGI6_v2.shp\")\n",
    "RGI6_ids = RGI6_ids[RGI6_ids.area_km2 > 1][[\"RGIId\", \"ID_basin\"]]\n",
    "\n",
    "RGI7_ids = gpd.read_file(\"/home/rooda/Dropbox/Patagonia/GIS South/Glaciers/RGI7_v2.shp\")\n",
    "RGI7_ids = RGI7_ids[RGI7_ids.area_km2 > 1]\n",
    "RGI7_ids = utils.cook_rgidf(RGI7_ids, o1_region='17', o2_region='02', bgndate= RGI7_ids.src_date, \n",
    "                            version = \"70\", assign_column_values= {'Zone' : 'Zone', 'ID_basin' : 'ID_basin'})\n",
    "RGI7_ids = RGI7_ids[[\"RGIId\", \"ID_basin\"]]\n",
    "\n",
    "# merge both datasets\n",
    "ids = pd.concat([RGI6_ids, RGI7_ids]).set_index(\"RGIId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6551a691-b2a4-4225-87b4-3ea55b862db4",
   "metadata": {},
   "source": [
    "### Historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bdc411-9bef-4de7-9604-70f73b7669b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(\"/home/rooda/OGGM_results/runs/*/run_outputs_*.nc\", recursive = True)\n",
    "ts_oggm  = xr.open_mfdataset(files, combine='nested', concat_dim=\"options\", chunks=\"auto\", parallel=True, preprocess=preprocess)\n",
    "\n",
    "# aggregate by catchment\n",
    "ids_subset = ids[ids.index.isin(ts_oggm.rgi_id.to_pandas().tolist())]\n",
    "ts_oggm   = ts_oggm.assign_coords(rgi_id = ids_subset.ID_basin.tolist())\n",
    "ts_oggm   = ts_oggm.groupby('rgi_id').sum().chunk(\"auto\")\n",
    "ts_oggm   = compute_variables(ts_oggm)\n",
    "ts_oggm   = ts_oggm.assign_coords(options=('options', [i.split(\"/\")[5][:-4] for i in files]))\n",
    "ts_oggm.to_netcdf(\"/home/rooda/OGGM_results/runs/OGGM_historical.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5868fad0-9596-4b88-bde5-ac325c3fcae5",
   "metadata": {},
   "source": [
    "### Future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468c42af-a099-492f-b0ca-7d366acadb64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scenarios        = [\"ct_random\", \"ssp126\", \"ssp245\", \"ssp370\", \"ssp585\"]\n",
    "scenarios        = [\"ct_random\"]\n",
    "\n",
    "for scenario in tqdm(scenarios): \n",
    "    files     = glob(\"/home/rooda/OGGM_results/runs/*/run_output_*\" + scenario + \"*.nc\", recursive = True)\n",
    "    ts_oggm   = xr.open_mfdataset(files, combine='nested', concat_dim=\"options\", chunks=\"auto\", parallel=False, preprocess=preprocess)\n",
    "\n",
    "    if scenario == \"ct_random\":\n",
    "        ts_oggm[\"time\"] = ts_oggm[\"time\"] + 2020\n",
    "\n",
    "    # aggregate by catchment\n",
    "    ids_subset = ids[ids.index.isin(ts_oggm.rgi_id.to_pandas().tolist())]\n",
    "    ts_oggm   = ts_oggm.assign_coords(rgi_id = ids_subset.ID_basin.tolist())\n",
    "    ts_oggm   = ts_oggm.groupby('rgi_id').sum().chunk(\"auto\").load()\n",
    "    \n",
    "    # compute all variables\n",
    "    ts_oggm   = compute_variables(ts_oggm)\n",
    "    ts_oggm   = ts_oggm.isel(time = slice(0, -1)) # last year with zeros\n",
    "    ts_oggm   = ts_oggm.assign_coords(options = [scenario] * len(files))\n",
    "    ts_oggm.to_netcdf(\"/home/rooda/OGGM_results/runs/OGGM_future_v2_{}.nc\".format(scenario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40372fe6-55cd-4612-b675-d2254fe21e99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
