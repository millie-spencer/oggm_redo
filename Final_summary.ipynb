{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "192a8bfd-20a7-4d37-9556-9ecba759d641",
   "metadata": {},
   "source": [
    "# Dataset for Zenodo repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a970de23-7bc7-44eb-b1e2-7a63079a41fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# basic\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# spatial\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import shapely.geometry\n",
    "import xesmf as xe\n",
    "import regionmask\n",
    "\n",
    "# climate\n",
    "from xclim.indicators import atmos\n",
    "from xclim import core \n",
    "\n",
    "# others\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "os.chdir('/home/rooda/Dropbox/Patagonia')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e3b1b4-391e-4004-bb47-031800400f01",
   "metadata": {},
   "source": [
    "## \"basins_boundaries.zip\" file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12061f5-03fc-44f8-b178-9212eb885c9d",
   "metadata": {},
   "source": [
    "Contains the polygons (in .shp format) of the studied catchments. Each catchment is identified by its \"basin_id\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43ee063-0174-4f0d-919f-590c59d2437a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basins = gpd.read_file(\"GIS South/Basins_Patagonia_ice.shp\")\n",
    "basins = basins.set_index(\"ID\")\n",
    "\n",
    "names = [\"Yelcho\", \"Baker\", \"Santa Cruz\", \"Palena\", \"Grey\", \"Puelo\", \"Cisnes\", \"Aysen\", \"Pascua\"]\n",
    "basins.loc[basins.basin_area > 5000, \"Name\"] = names\n",
    "basins = basins.replace({\"Zone\": {1:'PPY', 2:'PCA', 3:'NPI-E', 4:'NPI-W', 5:'SPI-N', 6:'SPI-C', 7:'SPI-S', 8:'GCN', 9:'CDI'}})\n",
    "basins = basins[[\"Name\", \"Zone\", \"basin_area\", \"geometry\"]]\n",
    "basins = basins.rename(columns = {\"Name\": \"basin_name\", \"Zone\": \"basin_zone\"})\n",
    "\n",
    "basins.index.name='basin_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074a4d99-f6d5-4a7a-97b5-f78d0b2b171f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basins\n",
    "basins.to_file(\"MS2 Results/zenodo/basins_boundaries.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8cb71f-bbcc-417e-99bd-531692bf2e5c",
   "metadata": {},
   "source": [
    "## \"dataset_historical.csv\" file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd83e26e-6ad4-4bb3-b36d-f800fd8bc693",
   "metadata": {},
   "source": [
    "Summarises the historical conditions of each glacier at the basin scale (area, volume and reference climate). The climate varaibles are estimated only using glacierized grid cells (1980-2019). \n",
    "- `basin_id`: unique identifier\n",
    "- `basin_name`: basin name (only for catchments with area over 5000 km2)\n",
    "- `basin_zone`: hydrological zone \n",
    "- `basin_area`: area of the basin in km2\t\n",
    "- `n_RGIX`: number of glaciers according to RGI6 and RGI7 inventories\n",
    "- `area_RGIX`: glacier area in km2 according to inventories RGI6 and RGI7\t\t\n",
    "- `vol_X`: glacier volume in km3 estimated from Farinnoti et al. (2019) [F19] and Millan et al. (2022) [M22]\t\n",
    "- `PP_X`: annual mean precipitation according to PMET v1.0, ERA5, MSWEP v2.8 and CR2MET v2.5\n",
    "- `PRSN_X`: annual mean solid precipitation according to PMET v1.0, ERA5, MSWEP v2.8 and CR2MET v2.5\n",
    "- `PP_X`: annual mean temperature according to PMET v1.0, ERA5, MSWEP v2.8 and CR2MET v2.5\n",
    "- `PPD_X`: annual mean positive degree-day sum according to PMET v1.0, ERA5, MSWX and CR2MET v2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa357f-c6a9-4e9f-b07f-fd4566977dec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add area, volume and number of glaciers\n",
    "RGI6 = gpd.read_file(\"GIS South/Glaciers/RGI6_v2.shp\")\n",
    "RGI7 = gpd.read_file(\"GIS South/Glaciers/RGI7_v2.shp\")\n",
    "glaciers  = pd.concat([RGI6.geometry, RGI7.geometry])\n",
    "glaciers  = glaciers.buffer(0.05) # mask to use for baseline climate\n",
    "\n",
    "RGI6_sum = RGI6.groupby(\"ID_basin\")[[\"O2Region\", \"area_km2\", \"vol_F19\", \"vol_M22\"]].sum()\n",
    "RGI6_sum = RGI6_sum.rename(columns = {\"O2Region\": \"n_RGI6\", \"area_km2\": \"area_RGI6\"})\n",
    "\n",
    "RGI7_sum = RGI7.groupby(\"ID_basin\")[[\"O2Region\", \"area_km2\"]].sum()\n",
    "RGI7_sum = RGI7_sum.rename(columns = {\"O2Region\": \"n_RGI7\", \"area_km2\": \"area_RGI7\"})\n",
    "\n",
    "basins = pd.concat([basins, RGI6_sum, RGI7_sum], axis=1)\n",
    "\n",
    "# fill with zeros\n",
    "fillc = [\"n_RGI6\", \"area_RGI6\", \"vol_F19\", \"vol_M22\", \"n_RGI7\", \"area_RGI7\"]\n",
    "basins[fillc] = basins[fillc].fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4d4d41-c4ff-4647-93c3-310610b013dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original (no regrid) reference climate (1980-2019): \n",
    "pp_pmet  = xr.open_dataset(\"/home/rooda/OGGM_results/PMET_OGGM_1980_2019m.nc\").prcp\n",
    "t2m_pmet = xr.open_dataset(\"/home/rooda/OGGM_results/PMET_OGGM_1980_2019m.nc\").temp\n",
    "dem_005  = xr.open_dataset(\"/home/rooda/OGGM_results/PMET_OGGM_1980_2019m.nc\").hgt\n",
    "\n",
    "pp_cr2met  = xr.open_dataset(\"/home/rooda/OGGM_results/CR2MET_OGGM_1980_2019m.nc\").prcp\n",
    "t2m_cr2met = xr.open_dataset(\"/home/rooda/OGGM_results/CR2MET_OGGM_1980_2019m.nc\").temp\n",
    "\n",
    "pp_mswep  = xr.open_dataset(\"/home/rooda/OGGM_results/MSWEP_OGGM_1980_2019m.nc\").prcp\n",
    "t2m_mswep = xr.open_dataset(\"/home/rooda/OGGM_results/MSWEP_OGGM_1980_2019m.nc\").temp\n",
    "dem_010   = xr.open_dataset(\"/home/rooda/OGGM_results/MSWEP_OGGM_1980_2019m.nc\").hgt\n",
    "regridder = xe.Regridder(dem_010,   dem_005, \"nearest_s2d\")\n",
    "dem_010   = regridder(dem_010)\n",
    "\n",
    "pp_era5   = xr.open_dataset(\"/home/rooda/OGGM_results/ERA5_OGGM_1980_2019m.nc\").prcp\n",
    "t2m_era5  = xr.open_dataset(\"/home/rooda/OGGM_results/ERA5_OGGM_1980_2019m.nc\").temp\n",
    "dem_025   = xr.open_dataset(\"/home/rooda/OGGM_results/ERA5_OGGM_1980_2019m.nc\").hgt\n",
    "regridder = xe.Regridder(dem_025,   dem_005, \"nearest_s2d\")\n",
    "dem_025   = regridder(dem_025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eea3fcb-6d5a-4d64-923b-29182e60fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regrid (PMET as the reference grid; 0.05ยบ)\n",
    "\n",
    "regridder  = xe.Regridder(pp_era5,   pp_pmet, \"nearest_s2d\")\n",
    "pp_era5    = regridder(pp_era5)\n",
    "regridder  = xe.Regridder(pp_cr2met, pp_pmet, \"nearest_s2d\")\n",
    "pp_cr2met  = regridder(pp_cr2met)\n",
    "regridder  = xe.Regridder(pp_mswep,  pp_pmet, \"nearest_s2d\")\n",
    "pp_mswep   = regridder(pp_mswep)\n",
    "\n",
    "lapse_rate = 0.0065 \n",
    "\n",
    "regridder  = xe.Regridder(t2m_era5,   t2m_pmet, \"nearest_s2d\")\n",
    "t2m_era5   = regridder(t2m_era5) # fake high res\n",
    "factor     = (dem_025 - dem_005)*lapse_rate\n",
    "t2m_era5   =  t2m_era5 + factor # \"real\" high res\n",
    "\n",
    "regridder  = xe.Regridder(t2m_mswep,   t2m_pmet, \"nearest_s2d\")\n",
    "t2m_mswep  = regridder(t2m_mswep) # fake high res\n",
    "factor     = (dem_010 - dem_005)*lapse_rate\n",
    "t2m_mswep  =  t2m_mswep + factor # \"real\" high res\n",
    "\n",
    "regridder  = xe.Regridder(t2m_cr2met, t2m_pmet, \"bilinear\")\n",
    "t2m_cr2met = regridder(t2m_cr2met) # simple case (same resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f8099d-1885-43f6-bd81-e10f1ee62090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mask: only glaciarated area\n",
    "mask      = regionmask.mask_geopandas(glaciers, pp_pmet)   >= 0\n",
    "\n",
    "pp_pmet    = pp_pmet.where(mask, drop = True)\n",
    "pp_era5    = pp_era5.where(mask, drop = True)\n",
    "pp_cr2met  = pp_cr2met.where(mask, drop = True)\n",
    "pp_mswep   = pp_mswep.where(mask, drop = True)\n",
    "\n",
    "t2m_pmet   = t2m_pmet.where(mask, drop = True)\n",
    "t2m_era5   = t2m_era5.where(mask, drop = True)\n",
    "t2m_cr2met = t2m_cr2met.where(mask, drop = True)\n",
    "t2m_mswep  = t2m_mswep.where(mask, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a69521-f549-4434-8916-e991f04bea0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate more variables\n",
    "\n",
    "# xclim needs the units\n",
    "pp_pmet.attrs['units']   = \"mm month-1\"\n",
    "pp_era5.attrs['units']   = \"mm month-1\"\n",
    "pp_cr2met.attrs['units'] = \"mm month-1\"\n",
    "pp_mswep.attrs['units']  = \"mm month-1\"\n",
    "t2m_pmet.attrs['units']   = \"C\"\n",
    "t2m_era5.attrs['units']   = \"C\"\n",
    "t2m_cr2met.attrs['units'] = \"C\"\n",
    "t2m_mswep.attrs['units']  = \"C\"\n",
    "\n",
    "# Positive degree-day sum (PDD)\n",
    "ppd_pmet   = t2m_pmet.where(t2m_pmet >= -1)\n",
    "ppd_era5   = t2m_era5.where(t2m_era5 >= -1)\n",
    "ppd_cr2met = t2m_cr2met.where(t2m_cr2met >= -1)\n",
    "ppd_mswep  = t2m_mswep.where(t2m_mswep >= -1)\n",
    "\n",
    "# snowfall component\n",
    "prsn_pmet = atmos.snowfall_approximation(pp_pmet, t2m_pmet, method='brown', thresh='0 degC')\n",
    "prsn_pmet = core.units.convert_units_to(prsn_pmet, target = 'mm month-1', context = \"hydro\")\n",
    "prsn_era5 = atmos.snowfall_approximation(pp_era5, t2m_era5, method='brown', thresh='0 degC')\n",
    "prsn_era5 = core.units.convert_units_to(prsn_era5, target = 'mm month-1', context = \"hydro\")\n",
    "prsn_cr2met = atmos.snowfall_approximation(pp_cr2met, t2m_cr2met, method='brown', thresh='0 degC')\n",
    "prsn_cr2met = core.units.convert_units_to(prsn_cr2met, target = 'mm month-1', context = \"hydro\")\n",
    "prsn_mswep = atmos.snowfall_approximation(pp_mswep, t2m_mswep, method='brown', thresh='0 degC')\n",
    "prsn_mswep = core.units.convert_units_to(prsn_mswep, target = 'mm month-1', context = \"hydro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88542bd-3ce9-4662-aa02-d8a4d05ce028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# annual value\n",
    "pp_pmet    = pp_pmet.resample(time='1Y').sum(skipna = False).mean(dim=\"time\")\n",
    "pp_era5    = pp_era5.resample(time='1Y').sum(skipna = False).mean(dim=\"time\")\n",
    "pp_cr2met  = pp_cr2met.resample(time='1Y').sum(skipna = False).mean(dim=\"time\")\n",
    "pp_mswep   = pp_mswep.resample(time='1Y').sum(skipna = False).mean(dim=\"time\")\n",
    "\n",
    "prsn_pmet    = prsn_pmet.resample(time='1Y').sum(skipna = False).mean(dim=\"time\")\n",
    "prsn_era5    = prsn_era5.resample(time='1Y').sum(skipna = False).mean(dim=\"time\")\n",
    "prsn_cr2met  = prsn_cr2met.resample(time='1Y').sum(skipna = False).mean(dim=\"time\")\n",
    "prsn_mswep   = prsn_mswep.resample(time='1Y').sum(skipna = False).mean(dim=\"time\")\n",
    "\n",
    "t2m_pmet   = t2m_pmet.resample(time='1Y').mean(skipna = False).mean(dim=\"time\")\n",
    "t2m_era5   = t2m_era5.resample(time='1Y').mean(skipna = False).mean(dim=\"time\")\n",
    "t2m_cr2met = t2m_cr2met.resample(time='1Y').mean(skipna = False).mean(dim=\"time\")\n",
    "t2m_mswep  = t2m_mswep.resample(time='1Y').mean(skipna = False).mean(dim=\"time\")\n",
    "\n",
    "# the +1 es due to threshold of -1ยบC\n",
    "ppd_pmet   = (ppd_pmet   + 1).resample(time='1Y').sum(skipna = True).mean(dim=\"time\")\n",
    "ppd_era5   = (ppd_era5   + 1).resample(time='1Y').sum(skipna = True).mean(dim=\"time\")\n",
    "ppd_cr2met = (ppd_cr2met + 1).resample(time='1Y').sum(skipna = True).mean(dim=\"time\")\n",
    "ppd_mswep  = (ppd_mswep  + 1).resample(time='1Y').sum(skipna = True).mean(dim=\"time\")\n",
    "\n",
    "ppd_pmet   = ppd_pmet.where(ppd_pmet > 0) * 30 # from monthly to daily (doesnt change anything)\n",
    "ppd_era5   = ppd_era5.where(ppd_era5 > 0) * 30\n",
    "ppd_cr2met = ppd_cr2met.where(ppd_cr2met > 0) * 30\n",
    "ppd_mswep  = ppd_mswep.where(ppd_mswep > 0) * 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe52ef2-de4b-45f1-9d2d-81078ae65543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean value for each catchment\n",
    "averager   = xe.SpatialAverager(pp_pmet,   basins.geometry, geom_dim_name=\"avg\")\n",
    "\n",
    "basins[\"PP_PMET\"]   = averager(pp_pmet,   skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"PP_ERA5\"]   = averager(pp_era5,   skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"PP_CR2MET\"] = averager(pp_cr2met, skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"PP_MSWEP\"]  = averager(pp_mswep,  skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "\n",
    "basins[\"PRSN_PMET\"]   = averager(prsn_pmet,   skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"PRSN_ERA5\"]   = averager(prsn_era5,   skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"PRSN_CR2MET\"] = averager(prsn_cr2met, skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"PRSN_MSWEP\"]  = averager(prsn_mswep,  skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "\n",
    "basins[\"T2M_PMET\"]   = averager(t2m_pmet,   skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"T2M_ERA5\"]   = averager(t2m_era5,   skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"T2M_CR2MET\"] = averager(t2m_cr2met, skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"T2M_MSWEP\"]  = averager(t2m_mswep,  skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "\n",
    "basins[\"PPD_PMET\"]   = averager(ppd_pmet,   skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"PPD_ERA5\"]   = averager(ppd_era5,   skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"PPD_CR2MET\"] = averager(ppd_cr2met, skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"PPD_MSWEP\"]  = averager(ppd_mswep,  skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350fa77a-7893-43ba-8db3-bcdd5a1b1f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basins\n",
    "basins = basins.drop(columns = \"geometry\").to_csv(\"MS2 Results/zenodo/dataset_historical.csv\",  index_label='basin_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e837011-ec42-4333-9869-d7751d10159d",
   "metadata": {},
   "source": [
    "## \"dataset_future.csv\" file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8413cf-7c65-4644-81e0-d3d501457203",
   "metadata": {},
   "source": [
    "Summarises the future glacier climate drivers and their impacts at the catchment scale: \n",
    "- `basin_id`: unique identifier \n",
    "- `basin_name`: basin name (only for catchments with area over 5000 km2)\n",
    "- `PPc_sspX`: relative precipitation change between the periods 1980-2015 and 2070-2099. Each column represents a different SSP scenario.\n",
    "- `PPc_spread`: number of GCM that agrees in the direction of change based on SSP 2-4.5 scenario\n",
    "- `T2Mc_sspX`: absolute temperature change between the periods 1980-2015 and 2070-2099. Each column represents a different SSP scenario.\n",
    "- `mass_loss_sspX`: mean mass loss in 2100 for each catchment. Each column represents a different SSP scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1529b0c-b066-4da3-be02-baa351f45ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_coords = np.arange(-56,-40, 0.5)\n",
    "lon_coords = np.arange(-76,-67, 0.5)\n",
    "\n",
    "baseline_period = slice(\"1980-01-01\", \"2015-01-01\")\n",
    "future_period   = slice(\"2070-01-01\", \"2100-01-01\")\n",
    "\n",
    "gcm_list  = [\"ACCESS-CM2\", \"BCC-CSM2-MR\", \"CMCC-ESM2\", \"FGOALS-f3-L\", \"GFDL-ESM4\", \"CMCC-CM2-SR5\", \"KACE-1-0-G\", \"MPI-ESM1-2-HR\", \"MRI-ESM2-0\", \"MIROC6\"]\n",
    "ssp_list  = ['ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "\n",
    "results_pp = []\n",
    "results_t2m = []\n",
    "\n",
    "for ssp in tqdm(ssp_list):\n",
    "    \n",
    "    results_gcm_pp  = []\n",
    "    results_gcm_t2m = []\n",
    "    \n",
    "    for gcm in gcm_list:\n",
    "        \n",
    "        pp_model_ssp = xr.open_dataset(\"/home/rooda/OGGM_results/Future_climate/PP_\" + gcm + \"_\" + ssp + \".nc\")[\"pr\"]\n",
    "        pp_model_ssp = pp_model_ssp.interp(lat = lat_coords, lon = lon_coords)\n",
    "        pp_model_ssp = core.units.convert_units_to(pp_model_ssp, target = 'mm month-1', context = \"hydro\").resample(time = \"YS\").sum()\n",
    "        pp_change    = (pp_model_ssp.sel(time = future_period).mean(dim=\"time\") / pp_model_ssp.sel(time = baseline_period).mean(dim=\"time\"))-1\n",
    "        results_gcm_pp.append(pp_change)\n",
    "        \n",
    "        t2m_model_ssp = xr.open_dataset(\"/home/rooda/OGGM_results/Future_climate/T2M_\" + gcm + \"_\" + ssp + \".nc\")[\"tas\"]\n",
    "        t2m_model_ssp = t2m_model_ssp.interp(lat = lat_coords, lon = lon_coords)\n",
    "        t2m_model_ssp = t2m_model_ssp.resample(time='YS').mean()        \n",
    "        t2m_change    = t2m_model_ssp.sel(time = future_period).mean(dim=\"time\") - t2m_model_ssp.sel(time = baseline_period).mean(dim=\"time\")\n",
    "        results_gcm_t2m.append(t2m_change)\n",
    "        \n",
    "    results_gcm_pp  = xr.concat(results_gcm_pp,  dim='gcm')\n",
    "    results_gcm_t2m = xr.concat(results_gcm_t2m, dim='gcm')\n",
    "    results_pp.append(results_gcm_pp)\n",
    "    results_t2m.append(results_gcm_t2m)\n",
    "    \n",
    "dataset = xr.merge([xr.concat(results_pp,  dim='ssp'), \n",
    "                    xr.concat(results_t2m, dim='ssp')])\n",
    "\n",
    "# GCM uncertainty (SSP 245) > 80% of the models should agree the direction\n",
    "gcm_spread = dataset.pr[2].where(dataset.pr[1] >= 0, 1).where(dataset.pr[2] < 0, -1).sum(dim = \"gcm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce783d2-dbed-4f20-bed8-90dd03eb0db2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## resample using ESMF.RegridMethod.NEAREST_STOD\n",
    "regridder  = xe.Regridder(dataset,  pp_pmet, \"bilinear\")\n",
    "dataset    = regridder(dataset)\n",
    "gcm_spread = regridder(gcm_spread)\n",
    "\n",
    "# only glacier area\n",
    "mask    = regionmask.mask_geopandas(glaciers, dataset)   >= 0\n",
    "dataset = dataset.where(mask, drop = True)\n",
    "gcm_spread = gcm_spread.where(mask, drop = True)\n",
    "\n",
    "# multi-model mean\n",
    "dataset = dataset.mean(dim = \"gcm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e103e49-92f7-4ebf-8693-5f33fe1f7e44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select SSP 245 for map (a,b)\n",
    "savg  = xe.SpatialAverager(dataset,  basins.geometry, geom_dim_name=\"avg\")\n",
    "\n",
    "basins[\"PPc_ssp126\"] = savg(dataset.pr[0], skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values*100\n",
    "basins[\"PPc_ssp245\"] = savg(dataset.pr[1], skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values*100\n",
    "basins[\"PPc_ssp370\"] = savg(dataset.pr[2], skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values*100\n",
    "basins[\"PPc_ssp585\"] = savg(dataset.pr[3], skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values*100\n",
    "basins[\"PPc_spread\"]     = savg(gcm_spread, skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "\n",
    "basins[\"T2Mc_ssp126\"] = savg(dataset.tas[0], skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"T2Mc_ssp245\"] = savg(dataset.tas[1], skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"T2Mc_ssp370\"] = savg(dataset.tas[2], skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"T2Mc_ssp585\"] = savg(dataset.tas[3], skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e69f89f-e5f6-4793-b7d8-c875def09271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# volume change\n",
    "RGI6_ids = RGI6[RGI6.area_km2 > 1][[\"RGIId\", \"ID_basin\"]]\n",
    "RGI7_ids = RGI7[RGI7.area_km2 > 1]\n",
    "RGI7_ids = utils.cook_rgidf(RGI7_ids, o1_region='17', o2_region='02', bgndate= RGI7_ids.src_date, \n",
    "                            version = \"70\", assign_column_values= {'ID_basin' : 'ID_basin'})\n",
    "RGI7_ids = RGI7_ids[[\"RGIId\", \"ID_basin\"]]\n",
    "\n",
    "# merge both datasets\n",
    "ids = pd.concat([RGI6_ids, RGI7_ids]).set_index(\"RGIId\")\n",
    "\n",
    "def preprocess(ds): # remove unnecessary variables and coordinates\n",
    "    return ds.drop_vars(['hydro_year', 'hydro_month', 'calendar_year', 'calendar_month'])['volume']\n",
    "\n",
    "gdirs = glob(\"/home/rooda/OGGM_results/new/*\", recursive = True)\n",
    "\n",
    "ds    = []\n",
    "for gdir in tqdm(gdirs):\n",
    "\n",
    "    # read historical run \n",
    "    model_hist   = xr.open_mfdataset(gdir + \"/run_outputs_*.nc\", preprocess = preprocess)\n",
    "    model_hist   = model_hist.sel(time=2015).volume # check NAs\n",
    "\n",
    "    paths = glob(gdir + \"/run_output_*ssp*.nc\", recursive = True)\n",
    "    for path in tqdm(paths, leave = False):\n",
    "\n",
    "        # read future run and concatenate\n",
    "        model_future = xr.open_dataset(path)\n",
    "        model_future = preprocess(model_future).sel(time=2100)\n",
    "        model   = xr.concat([model_hist, model_future], dim = \"time\").load()\n",
    "\n",
    "        # add basin ID to each glacier ID (RGI_ID)\n",
    "        ids_subset = ids[ids.index.isin(model.rgi_id.to_pandas().tolist())]\n",
    "        model = model.assign_coords(rgi_id = ids_subset.ID_basin.tolist())\n",
    "        model = model.groupby('rgi_id').sum()\n",
    "        model = 1 - (model.sel(time = 2100) / model.sel(time = 2015))\n",
    "        \n",
    "        # ID of the setup\n",
    "        experiment_id = pd.Series(data = {'SSP':     os.path.basename(path).split(\"_\")[3]})\n",
    "        ds_model = pd.DataFrame(pd.concat([experiment_id, model.to_pandas()]), columns=['mass_loss']).transpose()\n",
    "        ds.append(ds_model)\n",
    "        \n",
    "ds = pd.concat(ds)\n",
    "ds = ds.groupby(\"SSP\").mean()\n",
    "ds = ds.transpose()\n",
    "ds = ds.rename(columns = {'ssp126': 'mass_loss_ssp126', 'ssp245': 'mass_loss_ssp245',\n",
    "                          'ssp370': 'mass_loss_ssp370', 'ssp585': 'mass_loss_ssp585'})\n",
    "basins\n",
    "basins = pd.concat([basins, ds], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306999a8-d413-4edb-bd70-1afe980e5f10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basins = basins[[\"basin_name\",\n",
    "                 'PPc_ssp126', 'PPc_ssp245', 'PPc_ssp370', 'PPc_ssp585', \"PPc_spread\", \n",
    "                 'T2Mc_ssp126','T2Mc_ssp245', 'T2Mc_ssp370', 'T2Mc_ssp585',\n",
    "                 'mass_loss_ssp126', 'mass_loss_ssp245', 'mass_loss_ssp370', 'mass_loss_ssp585']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f669064-834a-400b-bb69-b1952f48b5f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basins\n",
    "basins = basins.to_csv(\"MS2 Results/zenodo/dataset_future.csv\",  index_label='basin_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab484a7d-fd6f-4b9a-8a63-1df81714e75a",
   "metadata": {},
   "source": [
    "## \"dataset_signatures.csv\" file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c68644-13e4-44a3-bb29-974063688e6b",
   "metadata": {},
   "source": [
    "Summarises the  glacio-hydrological signatures for each catchment. The metrics are calculated for the variables \"glacier runoff (GR)\" and \"glacier melt (GM)\". The mean was calculated using the full ensemble of projections (n = 1920). The main source of uncertainty (SoU) in each catchment was the source that accumulated most RMSE loss. Details of the different metrics can be found in Table 1. The file presents the following columns: \n",
    "\n",
    "- `basin_id`: unique identifier for each catchment \n",
    "- `variable_interannual_var`: Inter-annual variability mean (mm yr-1). \n",
    "- `variable_lt_change`: Long-term trend mean (% dec-1).  \n",
    "- `variable_lt_trend`: Long-term change mean (%). \n",
    "- `variable_peak_water_duration`:\tPeak water duration mean (years). \n",
    "- `variable_peak_water_magnitude`: Peak water magnitude mean (mm yr-1).\n",
    "- `variable_peak_water_year`: Peak water year mean (year). \n",
    "- `variable_ref_magnitude`: Reference magnitude mean (mm yr-1).\n",
    "- `variable_seasonal_cont`: Reference seasonal contribution mean (%).\n",
    "- `variable_seasonal_shift`: Seasonal shift mean (%). \n",
    "- `variable_seasonal_var`: Reference seasonal variability mean (%).\n",
    "- `SoU_variable_interannual_var`: Main SoU of the inter-annual variability for each catchment.\n",
    "- `SoU_variable_lt_change`:  Main SoU of the long-term trend for each catchment.\n",
    "- `SoU_variable_lt_trend`:  Main SoU of the long-term change for each catchment.\n",
    "- `SoU_variable_peak_water_duration`:  Main SoU of the peak water duration for each catchment.\n",
    "- `SoU_variable_peak_water_magnitude`:  Main SoU of the peak water magnitude for each catchment.\n",
    "- `SoU_variable_peak_water_year`:  Main SoU of the peak water year for each catchment.\n",
    "- `SoU_variable_ref_magnitude`:  Main SoU of the reference magnitude for each catchment.\n",
    "- `SoU_variable_seasonal_cont`:  Main SoU of the reference seasonal contribution for each catchment.\n",
    "- `SoU_variable_seasonal_shift`:  Main SoU of the seasonal shift for each catchment.\n",
    "- `SoU_variable_seasonal_var`:  Main SoU of the reference seasonal variability for each catchment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4924a377-d873-4cc0-b2f2-9c396e13ee42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# glacio-hydrological signature\n",
    "metrics = pd.read_csv(\"MS2 Results/dataset_hydro_signatures.csv\")\n",
    "metrics = metrics.drop(columns = [\"Outline\", \"Climate\", \"Volume\", \"GCM\", \"SSP\", \"BCM\"])\n",
    "metrics = metrics.rename(columns = {\"Unnamed: 0\": \"variable\", \"Variable\": \"metric\"})\n",
    "metrics = metrics.groupby([\"metric\", \"variable\"]).mean().transpose()\n",
    "metrics = metrics.droplevel(0, axis=1) \n",
    "metrics.columns = np.concatenate((\"GM_\" + metrics.columns[0:10].values, \"GR_\" + metrics.columns[0:10].values), axis=0)\n",
    "metrics.index = metrics.index.astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931e88c9-30e7-492e-b804-142185547e95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_su = pd.read_csv(\"MS2 Results/feature_importance_rmse.csv\", index_col = 0)\n",
    "metrics_su['Most_important'] = metrics_su[[\"Outline\",\"Climate\", \"Volume\", \"GCM\", \"SSP\", \"BCM\"]].idxmax(axis=1)\n",
    "metrics_su = metrics_su.drop(columns = [\"Outline\", \"Climate\", \"Volume\", \"GCM\", \"SSP\", \"BCM\"])\n",
    "metrics_su = metrics_su.pivot(columns = [\"Variable\", \"Metric\"], values = \"Most_important\")\n",
    "metrics_su = metrics_su.droplevel(0, axis=1)\n",
    "metrics_su.columns = np.concatenate((\"SoU_GM_\" + metrics_su.columns[0:10].values, \"SoU_GR_\" + metrics_su.columns[0:10].values), axis=0)\n",
    "\n",
    "metrics_hydro = pd.concat([metrics, metrics_su], axis=1)\n",
    "metrics_hydro.to_csv(\"MS2 Results/zenodo/dataset_signatures.csv\",  index_label='basin_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288432c6-4a63-424f-8194-474dca26dd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
