{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Based on https://curly-space-meme-rjgqp54j94vhp5x7.github.dev/ \n",
    "* To set up, run: mamba activate oggm_env\n",
    "* Using oggm_env (Python 3.12.2) kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "import os \n",
    "import psutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import xarray_regrid # type: ignore\n",
    "# using regrid instead of tqdm because was having a lot of issues trying to import \n",
    "from datetime import datetime\n",
    "\n",
    "# geospatial\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "\n",
    "# oggm\n",
    "from oggm import cfg, utils, workflow, tasks\n",
    "from oggm.shop import gcm_climate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and possible options "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first line was initially \n",
    "# cfg.initialize(logging_level='WORKFLOW', future = True)\n",
    "but I deleted future because apparently that's not an accepted function? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 18:34:46: oggm.cfg: Reading default parameters from the OGGM `params.cfg` configuration file.\n",
      "2024-07-25 18:34:46: oggm.cfg: Multiprocessing switched OFF according to the parameter file.\n",
      "2024-07-25 18:34:46: oggm.cfg: Multiprocessing: using all available processors (N=2)\n",
      "2024-07-25 18:34:48: oggm.cfg: Multiprocessing switched ON after user settings.\n",
      "2024-07-25 18:34:48: oggm.cfg: PARAMS['baseline_climate'] changed from `GSWP3_W5E5` to ``.\n",
      "2024-07-25 18:34:48: oggm.cfg: WARNING: adding an unknown parameter `prcp_scaling_factor`:`1` to PARAMS.\n",
      "2024-07-25 18:34:48: oggm.cfg: PARAMS['hydro_month_sh'] changed from `4` to `1`.\n",
      "2024-07-25 18:34:48: oggm.cfg: PARAMS['hydro_month_nh'] changed from `10` to `1`.\n",
      "2024-07-25 18:34:48: oggm.cfg: WARNING: adding an unknown parameter `min_mu_star`:`5` to PARAMS.\n",
      "2024-07-25 18:34:48: oggm.cfg: WARNING: adding an unknown parameter `max_mu_star`:`800` to PARAMS.\n",
      "2024-07-25 18:34:48: oggm.cfg: PARAMS['store_model_geometry'] changed from `False` to `True`.\n",
      "2024-07-25 18:34:48: oggm.cfg: PARAMS['continue_on_error'] changed from `False` to `True`.\n",
      "2024-07-25 18:34:48: oggm.cfg: WARNING: adding an unknown parameter `use_winter_prcp_factor`:`False` to PARAMS.\n"
     ]
    }
   ],
   "source": [
    "cfg.initialize(logging_level='WORKFLOW')\n",
    "\n",
    "cfg.PARAMS['use_multiprocessing']  = True\n",
    "cfg.PARAMS['baseline_climate']     = ''\n",
    "cfg.PARAMS['prcp_scaling_factor']  = 1\n",
    "cfg.PARAMS['hydro_month_sh']       = 1\n",
    "cfg.PARAMS['hydro_month_nh']       = 1\n",
    "cfg.PARAMS['border']               = 80\n",
    "cfg.PARAMS['min_mu_star']          = 5\n",
    "cfg.PARAMS['max_mu_star']          = 800\n",
    "cfg.PARAMS['geodetic_mb_period']   = '2000-01-01_2020-01-01' \n",
    "cfg.PARAMS['store_model_geometry'] = True\n",
    "cfg.PARAMS['continue_on_error']    = True\n",
    "cfg.PARAMS['use_winter_prcp_factor'] = False\n",
    "\n",
    "# Potential historical scenario\n",
    "outlines    = [\"RGI7\"]      # Glacier outlines\n",
    "climate_ds  = [\"PMET\", \"CR2MET\", \"MSWEP\", \"ERA5\"]  # Climate baseline\n",
    "volume_ds   = [\"M22\", \"F19\"]            # Reference volume dataset \n",
    "\n",
    "# Potential future scenario\n",
    "gcm_list  = [\"ACCESS-CM2\", \"BCC-CSM2-MR\", \"CMCC-ESM2\", \"FGOALS-f3-L\", \"GFDL-ESM4\", \"CMCC-CM2-SR5\", \"KACE-1-0-G\", \"MPI-ESM1-2-HR\", \"MRI-ESM2-0\", \"MIROC6\"] # Climate models\n",
    "ssp_list  = [\"ssp126\",\"ssp245\", \"ssp370\", \"ssp585\"]   # Future scenarios\n",
    "bias_correction = [\"MVA\", \"DQM\", \"MBC\"]              # Bias correction method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration in the reference period (and commitment run)\n",
    "The complete workflow was divided according to tasks due to RAM limitations (only 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 18:34:54: oggm.cfg: PARAMS['use_rgi_area'] changed from `True` to `False`.\n",
      "2024-07-25 18:34:54: oggm.cfg: PARAMS['use_intersects'] changed from `True` to `False`.\n",
      "2024-07-25 18:34:54: oggm.cfg: PARAMS['rgi_version'] changed from `62` to `7`.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'src_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m cfg\u001b[38;5;241m.\u001b[39mPARAMS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgi_version\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m\n\u001b[1;32m     22\u001b[0m columns_ids \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglac_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGLIMSId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marea_km2\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArea\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglac_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZone\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZone\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     23\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvol_F19\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvol_F19\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvol_M22\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvol_M22\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdmdtda_21\u001b[39m\u001b[38;5;124m'\u001b[39m :\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdmdtda_21\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m---> 24\u001b[0m ids \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcook_rgidf(ids, o1_region\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m17\u001b[39m\u001b[38;5;124m'\u001b[39m, o2_region\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m02\u001b[39m\u001b[38;5;124m'\u001b[39m, bgndate\u001b[38;5;241m=\u001b[39m \u001b[43mids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc_date\u001b[49m, version \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m70\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m               assign_column_values\u001b[38;5;241m=\u001b[39m columns_ids)\n\u001b[1;32m     27\u001b[0m gdirs \u001b[38;5;241m=\u001b[39m workflow\u001b[38;5;241m.\u001b[39minit_glacier_directories(ids)\n\u001b[1;32m     28\u001b[0m workflow\u001b[38;5;241m.\u001b[39mexecute_entity_task(tasks\u001b[38;5;241m.\u001b[39mdefine_glacier_region, gdirs, source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNASADEM\u001b[39m\u001b[38;5;124m\"\u001b[39m);\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'src_date'"
     ]
    }
   ],
   "source": [
    "for rgi in outlines:\n",
    "    for file_id in climate_ds: \n",
    "        for volume in volume_ds:\n",
    "            \n",
    "            start = datetime.now()\n",
    "            \n",
    "            # ids = gpd.read_file(\"/home/hydro/Dropbox/Patagonia/GIS South/Glaciers/\" + rgi + \"_v2.shp\")\n",
    "            ids = ['RGI60-17.13009', 'RGI60-17.13011', 'RGI60-17.13013', 'RGI60-17.13014', 'RGI60-17.13018', 'RGI60-17.13020', 'RGI60-17.13021', \n",
    "                   'RGI60-17.13022', 'RGI60-17.13024', 'RGI60-17.13026', 'RGI60-17.13029', 'RGI60-17.13030', 'RGI60-17.13031', 'RGI60-17.13033', \n",
    "                   'RGI60-17.13034', 'RGI60-17.13044', 'RGI60-17.13045', 'RGI60-17.13047', 'RGI60-17.13049', 'RGI60-17.13050', 'RGI60-17.13051',\n",
    "                   'RGI60-17.13052', 'RGI60-17.13054', 'RGI60-17.13056', 'RGI60-17.13058'] \n",
    "            # had a command to only look at big glaciers but that doesn't serve in my case \n",
    "            \n",
    "            # cfg.PATHS['working_dir']  = \"/home/hydro/OGGM_results/\" + rgi + \"_\" + file_id + \"_\" + volume +\"_run\"\n",
    "            cfg.PATHS['working_dir']  = \"/workspaces/oggm_redo/oggm\" + rgi + \"_\" + file_id + \"_\" + volume +\"_run\"\n",
    "            cfg.PATHS['climate_file'] = \"/home/hydro/OGGM_results/\" + file_id + \"_OGGM_1980_2019m.nc\"\n",
    "\n",
    "            if rgi == \"RGI7\":\n",
    "                cfg.PARAMS['use_rgi_area'] = False\n",
    "                cfg.PARAMS['use_intersects'] = False\n",
    "                cfg.PARAMS['rgi_version'] = 7\n",
    "                \n",
    "                columns_ids = {'glac_id': 'GLIMSId', 'area_km2' : 'Area', 'glac_name': 'Name', 'Zone' : 'Zone', \n",
    "                               'vol_F19': 'vol_F19', 'vol_M22':'vol_M22', 'dmdtda_21' :'dmdtda_21'}\n",
    "                ids = utils.cook_rgidf(ids, o1_region='17', o2_region='02', bgndate= ids.src_date, version = \"70\",\n",
    "                              assign_column_values= columns_ids)\n",
    "                 \n",
    "                gdirs = workflow.init_glacier_directories(ids)\n",
    "                workflow.execute_entity_task(tasks.define_glacier_region, gdirs, source=\"NASADEM\");\n",
    "\n",
    "                task_list = [tasks.process_dem, tasks.simple_glacier_masks, tasks.elevation_band_flowline,\n",
    "                             tasks.fixed_dx_elevation_band_flowline, tasks.compute_downstream_line, tasks.compute_downstream_bedshape]\n",
    "             \n",
    "                for task in task_list:\n",
    "                    workflow.execute_entity_task(task, gdirs);\n",
    "\n",
    "            # write climate file for each glacier\n",
    "            workflow.execute_entity_task(tasks.process_custom_climate_data, gdirs);\n",
    "            \n",
    "            # calibration using huggonet et al. 2021            \n",
    "            ref_mb21 = ids.set_index(\"RGIId\").dmdtda_21*1000    \n",
    "            workflow.execute_entity_task(tasks.mu_star_calibration_from_geodetic_mb, \n",
    "                                             [(gdir, {'ref_mb': float(ref_mb21.loc[gdir.rgi_id])}) for gdir in gdirs]);\n",
    "            \n",
    "            # subset gdirs to avoid infinitive error messages\n",
    "            workflow.execute_entity_task(tasks.apparent_mb_from_any_mb, gdirs);\n",
    "            df = utils.compile_task_log(gdirs, task_names=[\"apparent_mb_from_any_mb\"])\n",
    "            df = df[df.apparent_mb_from_any_mb == \"SUCCESS\"]\n",
    "            gdirs = [gdir for gdir in gdirs if gdir.rgi_id in df.index.tolist()]\n",
    "\n",
    "            # inversion by catchment\n",
    "            for zone in range(1,10):\n",
    "                ids_subset = ids[ids.Zone == zone]\n",
    "                gdirs_subset = [gdir for gdir in gdirs if gdir.rgi_id in ids_subset.RGIId.tolist()]\n",
    "\n",
    "                if volume == \"M22\": # Millan et al. 2022 \n",
    "                    workflow.calibrate_inversion_from_consensus(gdirs_subset, volume_m3_reference = ids_subset.vol_M22.sum()*1e9,\n",
    "                                                                apply_fs_on_mismatch=True, error_on_mismatch=False, \n",
    "                                                                filter_inversion_output=True);\n",
    "                else: # Farinotti et al. 2019\n",
    "                    workflow.calibrate_inversion_from_consensus(gdirs_subset, volume_m3_reference = ids_subset.vol_F19.sum()*1e9,\n",
    "                                                                apply_fs_on_mismatch=True, error_on_mismatch=False, \n",
    "                                                                filter_inversion_output=True);\n",
    "            # ready to use (calibrate)\n",
    "            workflow.execute_entity_task(tasks.init_present_time_glacier, gdirs); \n",
    "\n",
    "            # calibration\n",
    "            workflow.execute_entity_task(tasks.run_with_hydro, \n",
    "                             [(gdir, {'ref_dmdtda': float(ref_mb21.loc[gdir.rgi_id])}) for gdir in gdirs], \n",
    "                             run_task = tasks.run_dynamic_mu_star_calibration, \n",
    "                             store_monthly_hydro=True, \n",
    "                             ys=1980,\n",
    "                             ye=2020,\n",
    "                             ref_area_from_y0=True,\n",
    "                             output_filesuffix= \"_\" + file_id,\n",
    "                             err_ref_dmdtda = 0.25*1000,\n",
    "                             mu_star_max_step_length = 10, \n",
    "                             maxiter = 20,         \n",
    "                             ignore_errors=True);\n",
    "\n",
    "            utils.compile_glacier_statistics(gdirs);  # save results\n",
    "            utils.compile_run_output(gdirs, input_filesuffix= \"_\" + file_id)\n",
    "\n",
    "            ## commitment run\n",
    "            workflow.execute_entity_task(tasks.run_with_hydro, gdirs,\n",
    "                                                 run_task = tasks.run_random_climate,\n",
    "                                                 seed = 123,\n",
    "                                                 nyears = 80, \n",
    "                                                 y0 = 2000, # central year of the random climate period. Has to be set!\n",
    "                                                 halfsize = 15, \n",
    "                                                 store_monthly_hydro = True, \n",
    "                                                 output_filesuffix = '_ct_random',\n",
    "                                                 init_model_filesuffix = \"_\" + file_id,  # this is important! Start from 2020 glacier\n",
    "                                                 ref_geometry_filesuffix = \"_\" + file_id,  # also use this as area reference\n",
    "                                                 ref_area_from_y0 = True)  # and keep the same reference area as for the hist simulations\n",
    "            utils.compile_run_output(gdirs, input_filesuffix='_ct_random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climate projections for each glacier and scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rgi in outlines:\n",
    "    for file_id in climate_ds: \n",
    "        for volume in volume_ds:\n",
    "\n",
    "            ids = gpd.read_file(\"/home/hydro/Dropbox/Patagonia/GIS South/Glaciers/\" + rgi + \"_v2.shp\")\n",
    "            ids = ids[ids.area_km2 > 1] # ~ 2,000 glaciers in each RGI\n",
    "            \n",
    "            cfg.PATHS['working_dir']  = \"/home/hydro/OGGM_results/\" + rgi + \"_\" + file_id + \"_\" + volume +\"_run\"\n",
    "            cfg.PATHS['climate_file'] = \"/home/hydro/OGGM_results/\" + file_id + \"_OGGM_1980_2019m.nc\"\n",
    "\n",
    "            if rgi == \"RGI6\":\n",
    "                # init directories\n",
    "                cfg.PARAMS['use_rgi_area'] = True\n",
    "                cfg.PARAMS['use_intersects'] = True\n",
    "                cfg.PARAMS['rgi_version'] = 62\n",
    "\n",
    "            if rgi == \"RGI7\":\n",
    "                cfg.PARAMS['use_rgi_area'] = False\n",
    "                cfg.PARAMS['use_intersects'] = False\n",
    "                cfg.PARAMS['rgi_version'] = 7\n",
    "                \n",
    "                columns_ids = {'glac_id': 'GLIMSId', 'area_km2' : 'Area', 'glac_name': 'Name', 'Zone' : 'Zone', \n",
    "                               'vol_F19': 'vol_F19', 'vol_M22':'vol_M22', 'dmdtda_21' :'dmdtda_21'}\n",
    "                ids = utils.cook_rgidf(ids, o1_region='17', o2_region='02', bgndate= ids.src_date, version = \"70\",\n",
    "                              assign_column_values= columns_ids)\n",
    "                 \n",
    "            gdirs = workflow.init_glacier_directories(ids)\n",
    "\n",
    "            # future projections\n",
    "            for gcm in tqdm(gcm_list):    \n",
    "                for ssp in tqdm(ssp_list, leave = False):\n",
    "                    for bc in bias_correction:\n",
    "                        rid = \"_{}_{}_{}\".format(gcm, ssp, bc)\n",
    "\n",
    "                        # write future climate file (SSP-based) for each glacier\n",
    "                        workflow.execute_entity_task(gcm_climate.process_cmip_data, gdirs, filesuffix =  rid, \n",
    "                                                 fpath_precip = \"/home/hydro/OGGM_results/Future_climate_bc/PP_\" + file_id + rid + \".nc\", \n",
    "                                                 fpath_temp = \"/home/hydro/OGGM_results/Future_climate_bc/T2M_\" + file_id + rid + \".nc\", \n",
    "                                                 apply_bias_correction=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glacier projections for each glacier and scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rgi in outlines:\n",
    "    for file_id in climate_ds: \n",
    "        for volume in volume_ds:\n",
    "\n",
    "            ids = gpd.read_file(\"/home/hydro/Dropbox/Patagonia/GIS South/Glaciers/\" + rgi + \"_v2.shp\")\n",
    "            ids = ids[ids.area_km2 > 1] # ~ 2,000 glaciers in each RGI\n",
    "            \n",
    "            cfg.PATHS['working_dir']  = \"/home/hydro/OGGM_results/\" + rgi + \"_\" + file_id + \"_\" + volume +\"_run\"\n",
    "            cfg.PATHS['climate_file'] = \"/home/hydro/OGGM_results/\" + file_id + \"_OGGM_1980_2019m.nc\"\n",
    "\n",
    "            if rgi == \"RGI6\":\n",
    "                # init directories\n",
    "                cfg.PARAMS['use_rgi_area'] = True\n",
    "                cfg.PARAMS['use_intersects'] = True\n",
    "                cfg.PARAMS['rgi_version'] = 62\n",
    "\n",
    "            if rgi == \"RGI7\":\n",
    "                cfg.PARAMS['use_rgi_area'] = False\n",
    "                cfg.PARAMS['use_intersects'] = False\n",
    "                cfg.PARAMS['rgi_version'] = 7\n",
    "                \n",
    "                columns_ids = {'glac_id': 'GLIMSId', 'area_km2' : 'Area', 'glac_name': 'Name', 'Zone' : 'Zone', \n",
    "                               'vol_F19': 'vol_F19', 'vol_M22':'vol_M22', 'dmdtda_21' :'dmdtda_21'}\n",
    "                ids = utils.cook_rgidf(ids, o1_region='17', o2_region='02', bgndate= ids.src_date, version = \"70\",\n",
    "                              assign_column_values= columns_ids)\n",
    "                 \n",
    "            gdirs = workflow.init_glacier_directories(ids)\n",
    "\n",
    "            # subset gdirs to avoid infinitive error messages\n",
    "            df = pd.read_csv(cfg.PATHS['working_dir'] + \"/task_log.csv\")\n",
    "            df = df[df.apparent_mb_from_any_mb == \"SUCCESS\"]\n",
    "            gdirs = [gdir for gdir in gdirs if gdir.rgi_id in df.rgi_id.tolist()]\n",
    "                \n",
    "            for gcm in tqdm(gcm_list):    \n",
    "                for ssp in tqdm(ssp_list):\n",
    "                    for bc in bias_correction:\n",
    "                        rid = \"_{}_{}_{}\".format(gcm, ssp, bc)\n",
    "\n",
    "                        # run the glacier using hydro function \n",
    "                        workflow.execute_entity_task(tasks.run_with_hydro, gdirs, run_task = tasks.run_from_climate_data,\n",
    "                                                 climate_filename = 'gcm_data',  # use gcm_data, not climate_historical\n",
    "                                                 climate_input_filesuffix = rid,  # use the chosen scenario\n",
    "                                                 init_model_filesuffix = \"_\" + file_id,  # this is important! Start from 2020 glacier\n",
    "                                                 ref_geometry_filesuffix = \"_\" + file_id,  # also use this as area reference\n",
    "                                                 ref_area_from_y0 = True,  # and keep the same reference area as for the hist simulations\n",
    "                                                 output_filesuffix = rid,  # recognize the run for later\n",
    "                                                 store_monthly_hydro = True)  # add monthly diagnostics\n",
    "                        utils.compile_run_output(gdirs, input_filesuffix=rid)\n",
    "\n",
    "                    print(rgi, file_id, volume, gcm, ssp, datetime.now()-start, \"RAM memory % used:\", psutil.virtual_memory()[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
